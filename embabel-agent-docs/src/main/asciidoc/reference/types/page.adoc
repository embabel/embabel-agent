[[reference.types]]
=== Core Types

==== LlmOptions

The `LlmOptions` class specifies which LLM to use and its hyperparameters.
It's defined in the https://github.com/embabel/embabel-common[embabel-common] project and provides a fluent API for LLM configuration:

[source,java]
----
// Create LlmOptions with model and temperature
var options = LlmOptions
    .withModel(OpenAiModels.GPT_4O_MINI)
    .withTemperature(0.8);

// Use different hyperparameters for different tasks
var analyticalOptions = LlmOptions
    .withModel(OpenAiModels.GPT_4O_MINI)
    .withTemperature(0.2)
    .withTopP(0.9);
----

**Important Methods:**

- `withModel(String)`: Specify the model name
- `withRole(String)`: Specify the model role. The role must be one defined in configuration via `embabel.models.llms.<role>=<model-name>`
- `withTemperature(Double)`: Set creativity/randomness (0.0-1.0)
- `withTopP(Double)`: Set nucleus sampling parameter
- `withTopK(Integer)`: Set top-K sampling parameter
- `withPersona(String)`: Add a system message persona

`LlmOptions` is serializable to JSON, so you can set properties of type
`LlmOptions` in `application.yml` and other application configuration files.
This is a powerful way of externalizing not only models, but hyperparameters.

==== PromptRunner

All LLM calls in user applications should be made via the `PromptRunner` interface.
Once created, a `PromptRunner` can run multiple prompts with the same LLM, hyperparameters, tool groups and `PromptContributors`.

===== Getting a PromptRunner

You obtain a `PromptRunner` from an `OperationContext` using the fluent API:

[source,java]
----
@Action
public Story createStory(UserInput input, OperationContext context) {
    // Get PromptRunner with default LLM
    var runner = context.ai().withDefaultLlm();

    // Get PromptRunner with specific LLM options
    var customRunner = context.ai().withLlm(
        LlmOptions.withModel(OpenAiModels.GPT_4O_MINI)
            .withTemperature(0.8)
    );

    return customRunner.createObject("Write a story about: " + input.getContent(), Story.class);
}
----

===== PromptRunner Methods

**Core Object Creation:**

- `createObject(String, Class<T>)`: Create a typed object from a prompt, otherwise throw an exception. An exception triggers retry. If retry fails repeatedly, re-planning occurs.
- `createObjectIfPossible(String, Class<T>)`: Try to create an object, return null on failure.
This can cause replanning.
- `generateText(String)`: Generate simple text response

TIP: Normally you want to use one of the `createObject` methods to ensure the response is typed correctly.

**Tool and Context Management:**

- `withToolGroup(String)`: Add <<reference.tools__tool-groups, tool groups>> for LLM access
- `withToolObject(Object)`: Add domain objects with <<reference.tools, @Tool>> methods
- `withPromptContributor(PromptContributor)`: Add <<reference.prompt-contributors, context>> contributors

**LLM Configuration:**

- `withLlm(LlmOptions)`: Use specific LLM configuration
- `withGenerateExamples(Boolean)`: Control example generation

**Returning a Specific Type**

- `creating(Class<T>)`: Go into the `ObjectCreator` fluent API for returning a particular type.

For example:

[source,java]
----
var story = context.ai()
    .withDefaultLlm()
    .withToolGroup(CoreToolGroups.WEB)
    .creating(Story.class)
    .fromPrompt("Create a story about: " + input.getContent());
----

The main reason to do this is to add strongly typed examples for https://www.promptingguide.ai/techniques/fewshot[few-shot prompting].
For example:

[source,java]
----
var story = context.ai()
    .withDefaultLlm()
    .withToolGroup(CoreToolGroups.WEB)
    .withExample("A children's story", new Story("Once upon a time...")) // <1>
    .creating(Story.class)
    .fromPrompt("Create a story about: " + input.getContent());
----

<1> **Example**: The example will be included in the prompt in JSON format to guide the LLM.

**Advanced Features:**

- `withTemplate(String)`: Use <<reference.templates, Jinja>> templates for prompts
- `withSubagents(Subagent...)`: Enable handoffs to other agents
- `evaluateCondition(String, String)`: Evaluate boolean condition

**Validation**

Embabel supports JSR-380 bean validation annotations on domain objects.
When creating objects via `PromptRunner.createObject` or `createObjectIfPossible`, validation is automatically performed after deserialization.
If validation fails, Embabel transparently retries the LLM call to obtain a valid object,
describing the validation errors to the LLM to help it correct its response.

If validation fails a second time, `InvalidLlmReturnTypeException` is thrown.
This will trigger replanning if not caught.
You can also choose to catch it within the action method making the LLM call,
and take appropriate action in your own code.

// TODO: (jasper notes) Add links to subagent and evaluateCondition
